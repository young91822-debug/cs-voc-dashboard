# pages/01_ê´€ë¦¬ì.py
import io
import os
import time
from datetime import datetime

import pandas as pd
import streamlit as st

from utils import (
    save_master_bytes,
    load_master_updated_at,
)

st.set_page_config(page_title="ê´€ë¦¬ì", layout="wide")

# -----------------------------
# Admin Token (secrets.toml ì—†ì–´ë„ ì•ˆì£½ê²Œ / ì•ˆë‚´ë¬¸êµ¬ ì œê±°)
# -----------------------------
def s(v):
    return "" if v is None else str(v).strip()

def get_secret(key: str):
    v = os.environ.get(key)
    if v:
        return s(v)
    try:
        return s(st.secrets.get(key))
    except Exception:
        return ""

DEFAULT_TOKEN = get_secret("ADMIN_TOKEN") or "15886559"  # fallback (ì›í•˜ë©´ ë°”ê¿”)

st.title("ê´€ë¦¬ì í˜ì´ì§€")
st.caption("ì—‘ì…€ 1ê°œ ì—…ë¡œë“œ(ìœ ì„ /ì±„íŒ…/ê²Œì‹œíŒ ì‹œíŠ¸) â†’ í†µí•© master ì €ì¥ â†’ app(ëŒ€ì‹œë³´ë“œ)ì—ì„œ ìë™ ë¡œë“œ")

token = st.text_input("ê´€ë¦¬ì í† í°", type="password", value="")
ok = (s(token) == s(DEFAULT_TOKEN))

if ok:
    st.success("ê´€ë¦¬ì ì¸ì¦ ì™„ë£Œ âœ…")
else:
    st.warning("ê´€ë¦¬ì í† í°ì„ ì…ë ¥í•´ì•¼ ì—…ë¡œë“œ/ì €ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

# -----------------------------
# Paths (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
# -----------------------------
DATA_DIR = "data"
MASTER_XLSX = os.path.join(DATA_DIR, "master.xlsx")
MASTER_META = os.path.join(DATA_DIR, "master.meta")

# -----------------------------
# Reset (master ì´ˆê¸°í™”)
# -----------------------------
updated_at = load_master_updated_at(st) or "ì—†ìŒ (ì²˜ìŒì´ë©´ ì •ìƒ)"
st.info(f"í˜„ì¬ master ì—…ë°ì´íŠ¸: {updated_at}")

st.warning("âš ï¸ ì´ˆê¸°í™”(ë¦¬ì…‹)ë¥¼ ëˆ„ë¥´ë©´ í˜„ì¬ master ë°ì´í„°ê°€ ëª¨ë‘ ì‚­ì œë©ë‹ˆë‹¤. (ë³µêµ¬ ë¶ˆê°€)")

c_reset1, c_reset2 = st.columns([1.2, 2.8])
with c_reset1:
    agree = st.checkbox("ë³µêµ¬ ë¶ˆê°€ì— ë™ì˜", value=False)
with c_reset2:
    do_reset = st.button("ğŸ§¹ master ì´ˆê¸°í™”", use_container_width=True, disabled=not agree)

if do_reset:
    os.makedirs(DATA_DIR, exist_ok=True)
    removed = []
    for p in [MASTER_XLSX, MASTER_META]:
        try:
            if os.path.exists(p):
                os.remove(p)
                removed.append(os.path.basename(p))
        except Exception:
            pass

    # âœ… ìºì‹œê¹Œì§€ ê°™ì´ ì‚­ì œ (ëŒ€ì‹œë³´ë“œ ì”ìƒ ë°©ì§€)
    st.cache_data.clear()

    if removed:
        st.success(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {', '.join(removed)} ì‚­ì œë¨ (ëŒ€ì‹œë³´ë“œë„ ë°ì´í„° ì—†ìŒ ìƒíƒœ)")
    else:
        st.success("âœ… ì´ˆê¸°í™” ì™„ë£Œ: ì‚­ì œí•  master íŒŒì¼ì´ ì—†ì—ˆì–´ìš” (ì´ë¯¸ ì´ˆê¸° ìƒíƒœ)")
    time.sleep(0.2)
    st.rerun()

st.divider()

# -----------------------------
# One-file upload (Excel with 3 sheets)
# -----------------------------
st.subheader("ì—‘ì…€ 1ê°œ ì—…ë¡œë“œ (ì‹œíŠ¸: ìœ ì„  / ì±„íŒ… / ê²Œì‹œíŒ)")

st.caption(
    "ê° ì‹œíŠ¸ì˜ ì»¬ëŸ¼(í—¤ë”)ì€ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë§ì¶°ì£¼ì„¸ìš”.\n"
    "- (ê¶Œì¥) í—¤ë”: ì¸ì…ë‚ ì§œ, ì¸ì…ì‹œê°„, ê¸°ì—…ëª…, ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜, ì†Œë¶„ë¥˜\n"
    "- ë˜ëŠ” A~F ìˆœì„œê°€ ì •í™•íˆ: ì¸ì…ë‚ ì§œ / ì¸ì…ì‹œê°„ / ê¸°ì—…ëª… / ëŒ€ë¶„ë¥˜ / ì¤‘ë¶„ë¥˜ / ì†Œë¶„ë¥˜"
)

up = st.file_uploader("ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"], key="up_one")

SHEETS = ["ìœ ì„ ", "ì±„íŒ…", "ê²Œì‹œíŒ"]

def _excel_time_to_str(x):
    """ì—‘ì…€ ì‹œê°„(ìˆ«ì/ì‹œê°„/ë¬¸ì) â†’ 'HH:MM:SS'"""
    if pd.isna(x):
        return None
    # datetime.time
    if hasattr(x, "hour") and hasattr(x, "minute"):
        return f"{int(x.hour):02d}:{int(x.minute):02d}:{int(getattr(x, 'second', 0)):02d}"
    # ìˆ«ì(float): ì—‘ì…€ ì‹œê°„ ë¹„ìœ¨(1ì¼=1)
    try:
        if isinstance(x, (int, float)) and 0 <= float(x) < 1:
            total_seconds = int(round(float(x) * 24 * 60 * 60))
            hh = total_seconds // 3600
            mm = (total_seconds % 3600) // 60
            ss = total_seconds % 60
            return f"{hh:02d}:{mm:02d}:{ss:02d}"
    except Exception:
        pass
    # ë¬¸ìì—´
    t = str(x).strip()
    if not t:
        return None
    return t

def build_master_from_sheet(df_sheet: pd.DataFrame, channel_name: str) -> pd.DataFrame:
    if df_sheet is None or df_sheet.empty:
        raise ValueError(f"[{channel_name}] ì‹œíŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    df = df_sheet.copy()
    df.columns = [str(c).strip() for c in df.columns]

    # 1) í—¤ë”ëª…ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš°
    header_map = {
        "ì¸ì…ë‚ ì§œ": "ì¸ì…ë‚ ì§œ",
        "ì¸ì…ì‹œê°„": "ì¸ì…ì‹œê°„",
        "ê¸°ì—…ëª…": "ê¸°ì—…ëª…",
        "ëŒ€ë¶„ë¥˜": "ëŒ€ë¶„ë¥˜",
        "ì¤‘ë¶„ë¥˜": "ì¤‘ë¶„ë¥˜",
        "ì†Œë¶„ë¥˜": "ì†Œë¶„ë¥˜",
    }

    has_named = all(k in df.columns for k in header_map.keys())

    if not has_named:
        # 2) A~F ìˆœì„œ ê°•ì œ ë§¤í•‘ (ì²« 6ì»¬ëŸ¼)
        if df.shape[1] < 6:
            raise ValueError(f"[{channel_name}] ì»¬ëŸ¼ì´ 6ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼ìˆ˜={df.shape[1]}")
        cols6 = df.columns[:6].tolist()
        df = df.rename(
            columns={
                cols6[0]: "ì¸ì…ë‚ ì§œ",
                cols6[1]: "ì¸ì…ì‹œê°„",
                cols6[2]: "ê¸°ì—…ëª…",
                cols6[3]: "ëŒ€ë¶„ë¥˜",
                cols6[4]: "ì¤‘ë¶„ë¥˜",
                cols6[5]: "ì†Œë¶„ë¥˜",
            }
        )

    need = ["ì¸ì…ë‚ ì§œ", "ì¸ì…ì‹œê°„", "ê¸°ì—…ëª…", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]
    miss = [c for c in need if c not in df.columns]
    if miss:
        raise ValueError(f"[{channel_name}] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {miss} / ì‹¤ì œ: {df.columns.tolist()}")

    # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
    d = pd.to_datetime(df["ì¸ì…ë‚ ì§œ"], errors="coerce")
    t = df["ì¸ì…ì‹œê°„"].apply(_excel_time_to_str)
    dt = pd.to_datetime(d.dt.strftime("%Y-%m-%d") + " " + t.fillna("00:00:00"), errors="coerce")

    out = pd.DataFrame(
        {
            "ë‚ ì§œ": dt,
            "ê¸°ì—…ëª…": df["ê¸°ì—…ëª…"].astype(str).str.strip(),
            "ëŒ€ë¶„ë¥˜": df["ëŒ€ë¶„ë¥˜"].astype(str).str.strip(),
            "ì¤‘ë¶„ë¥˜": df["ì¤‘ë¶„ë¥˜"].astype(str).str.strip(),
            "ì†Œë¶„ë¥˜": df["ì†Œë¶„ë¥˜"].astype(str).str.strip(),
            "ì±„ë„": channel_name,
        }
    )

    out = out.dropna(subset=["ë‚ ì§œ"]).copy()

    # ë¹ˆê°’ ì •ë¦¬
    for c in ["ê¸°ì—…ëª…", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜", "ì±„ë„"]:
        out.loc[out[c].isin(["nan", "None", "NaN", ""]), c] = None

    return out

dfs = []
errors = []
counts = {k: 0 for k in SHEETS}

if up is not None:
    try:
        book = pd.ExcelFile(up)
        sheet_names = [str(x).strip() for x in book.sheet_names]

        # ì‹œíŠ¸ ì¡´ì¬ ì²´í¬(ìœ ì„ /ì±„íŒ…/ê²Œì‹œíŒ)
        missing_sheets = [s for s in SHEETS if s not in sheet_names]
        if missing_sheets:
            raise ValueError(f"ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤: {missing_sheets} / í˜„ì¬ ì‹œíŠ¸: {sheet_names}")

        for ch in SHEETS:
            try:
                df_sheet = pd.read_excel(book, sheet_name=ch)
                dm = build_master_from_sheet(df_sheet, ch)
                dfs.append(dm)
                counts[ch] = int(len(dm))
            except Exception as e:
                errors.append(f"[{ch}] ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    except Exception as e:
        errors.append(f"ì—‘ì…€ ì½ê¸° ì‹¤íŒ¨: {e}")

st.subheader("ì—…ë¡œë“œ ë¡œë“œ ê²°ê³¼(ì±„ë„ë³„ ê±´ìˆ˜)")
cc1, cc2, cc3 = st.columns(3)
cc1.metric("ìœ ì„ ", f"{counts['ìœ ì„ ']:,}ê±´")
cc2.metric("ì±„íŒ…", f"{counts['ì±„íŒ…']:,}ê±´")
cc3.metric("ê²Œì‹œíŒ", f"{counts['ê²Œì‹œíŒ']:,}ê±´")

if errors:
    st.error("ì—…ë¡œë“œ/ì „ì²˜ë¦¬ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.\n\n- " + "\n- ".join(errors))

can_save = (len(dfs) > 0) and (len(errors) == 0)

st.caption("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¯¸ë¦¬ë³´ê¸° ë° ì €ì¥ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

if dfs:
    st.markdown("#### ë¯¸ë¦¬ë³´ê¸°(í†µí•© í›„, ìƒìœ„ 80í–‰)")
    preview = pd.concat(dfs, ignore_index=True).head(80)
    st.dataframe(preview, use_container_width=True)

st.divider()

btn = st.button("ğŸ’¾ master ì €ì¥(í†µí•©) â€” ì €ì¥ ì‹œ ê¸°ì¡´ ë°ì´í„° ìë™ ì´ˆê¸°í™”", disabled=not can_save, use_container_width=True)

if btn:
    t0 = time.perf_counter()
    with st.spinner("í†µí•©/ì €ì¥ ì¤‘..."):
        merged = pd.concat(dfs, ignore_index=True)

        os.makedirs(DATA_DIR, exist_ok=True)

        out = io.BytesIO()
        with pd.ExcelWriter(out, engine="openpyxl") as w:
            merged.to_excel(w, index=False, sheet_name="master")

        b = out.getvalue()
        elapsed = time.perf_counter() - t0

        meta = {
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "rows": int(len(merged)),
            "save_seconds": round(float(elapsed), 3),
        }

        save_master_bytes(b, meta)

        # âœ… ëŒ€ì‹œë³´ë“œ ì”ìƒ ë°©ì§€ (ìºì‹œ í´ë¦¬ì–´)
        st.cache_data.clear()

    st.success("ì €ì¥ ì™„ë£Œ! ëŒ€ì‹œë³´ë“œ(app)ë¡œ ì´ë™í•˜ë©´ ë°”ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤ âœ…")
    st.caption(f"ì €ì¥ ì‹œê°„: {elapsed:.2f}ì´ˆ / rows: {len(merged):,}")
    time.sleep(0.2)
    st.rerun()
