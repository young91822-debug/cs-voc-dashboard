# pages/01_ê´€ë¦¬ì.py
import io
import os
import time
from datetime import datetime

import pandas as pd
import streamlit as st

from utils import (
    REQUIRED_COLS,
    CHANNELS,
    normalize_master_like,
    parse_date_series,
    save_master_bytes,
    load_master_updated_at,
)

st.set_page_config(page_title="ê´€ë¦¬ì", layout="wide")

# -----------------------------
# Admin Token (secrets.toml ì—†ì–´ë„ ì•ˆì£½ê²Œ)
# -----------------------------
def s(v):
    return "" if v is None else str(v).strip()

def get_secret(key: str):
    # 1) í™˜ê²½ë³€ìˆ˜ ìš°ì„ 
    v = os.environ.get(key)
    if v:
        return s(v)

    # 2) secrets.toml (ì—†ìœ¼ë©´ StreamlitSecretNotFoundError ë‚˜ë¯€ë¡œ try/except í•„ìˆ˜)
    try:
        return s(st.secrets.get(key))
    except Exception:
        return ""

DEFAULT_TOKEN = get_secret("ADMIN_TOKEN") or "15886559"  # fallback ìœ ì§€ (ì›í•˜ë©´ ë°”ê¿”)

st.title("ê´€ë¦¬ì í˜ì´ì§€")
st.caption("ìœ ì„ /ì±„íŒ…/ê²Œì‹œíŒ íŒŒì¼ ì—…ë¡œë“œ â†’ í†µí•© master ì €ì¥ â†’ app(ëŒ€ì‹œë³´ë“œ)ì—ì„œ ìë™ ë¡œë“œ")

# í† í°ì´ ê¸°ë³¸ê°’(í´ë°±)ìœ¼ë¡œ ì¡íŒ ê²½ìš° ì•ˆë‚´
if DEFAULT_TOKEN == "15886559":
    st.info(
        "âš ï¸ ADMIN_TOKENì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•Šì•„ ê¸°ë³¸ í† í°(15886559)ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.\n\n"
        "ì›í•˜ëŠ” í† í°ìœ¼ë¡œ ë°”ê¾¸ë ¤ë©´ ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ì„¤ì •í•˜ì„¸ìš”.\n"
        "- í”„ë¡œì íŠ¸ í´ë”ì— `.streamlit/secrets.toml` ìƒì„± í›„ `ADMIN_TOKEN = \"ì›í•˜ëŠ”ê°’\"`\n"
        "- ë˜ëŠ” PowerShellì—ì„œ ì‹¤í–‰ ì „ `$env:ADMIN_TOKEN=\"ì›í•˜ëŠ”ê°’\"`"
    )

token = st.text_input("ê´€ë¦¬ì í† í°", type="password", value="")
ok = (s(token) == s(DEFAULT_TOKEN))

if ok:
    st.success("ê´€ë¦¬ì ì¸ì¦ ì™„ë£Œ âœ…")
else:
    st.warning("ê´€ë¦¬ì í† í°ì„ ì…ë ¥í•´ì•¼ ì—…ë¡œë“œ/ì €ì¥ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    st.stop()

updated_at = load_master_updated_at(st) or "ì—†ìŒ (ì²˜ìŒì´ë©´ ì •ìƒ)"
st.info(f"í˜„ì¬ master ì—…ë°ì´íŠ¸: {updated_at}")

st.divider()

# -----------------------------
# Upload
# -----------------------------
c1, c2, c3 = st.columns(3, gap="large")
with c1:
    up_tel = st.file_uploader("ìœ ì„  íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"], key="up_tel")
with c2:
    up_chat = st.file_uploader("ì±„íŒ… íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"], key="up_chat")
with c3:
    up_board = st.file_uploader("ê²Œì‹œíŒ íŒŒì¼ ì—…ë¡œë“œ", type=["csv", "xlsx", "xls"], key="up_board")


def read_any(file):
    """csv/xlsx ìë™ ì½ê¸°"""
    if file is None:
        return None
    name = (file.name or "").lower()
    if name.endswith(".csv"):
        return pd.read_csv(file)
    return pd.read_excel(file)


def prep(df: pd.DataFrame, channel_name: str) -> pd.DataFrame:
    """
    utils.normalize_master_likeë¡œ ì»¬ëŸ¼ í‘œì¤€í™” í›„,
    REQUIRED_COLS + ì±„ë„ ì»¬ëŸ¼ìœ¼ë¡œ master í˜•íƒœë¡œ ì •ë¦¬
    """
    if df is None or df.empty:
        raise ValueError(f"[{channel_name}] íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    df = normalize_master_like(df)

    miss = [c for c in REQUIRED_COLS if c not in df.columns]
    if miss:
        raise ValueError(f"[{channel_name}] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {miss} / ì‹¤ì œ: {df.columns.tolist()}")

    df = df[REQUIRED_COLS].copy()
    df["ë‚ ì§œ"] = parse_date_series(df["ë‚ ì§œ"])
    df = df[df["ë‚ ì§œ"].notna()].copy()

    df["ì±„ë„"] = channel_name
    for c in ["ê¸°ì—…ëª…", "ëŒ€ë¶„ë¥˜", "ì¤‘ë¶„ë¥˜", "ì†Œë¶„ë¥˜"]:
        df[c] = df[c].astype(str).str.strip()

    df["ì±„ë„"] = df["ì±„ë„"].astype(str).str.strip()
    return df


dfs = []
errors = []
counts = {"ìœ ì„ ": 0, "ì±„íŒ…": 0, "ê²Œì‹œíŒ": 0}

for file_obj, ch in [(up_tel, "ìœ ì„ "), (up_chat, "ì±„íŒ…"), (up_board, "ê²Œì‹œíŒ")]:
    if file_obj is None:
        continue
    try:
        d0 = read_any(file_obj)
        d1 = prep(d0, ch)
        dfs.append(d1)
        counts[ch] = int(len(d1))
    except Exception as e:
        errors.append(f"[{ch}] {getattr(file_obj, 'name', 'íŒŒì¼')} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

st.subheader("ì—…ë¡œë“œ ë¡œë“œ ê²°ê³¼(ì±„ë„ë³„ ê±´ìˆ˜)")
cc1, cc2, cc3 = st.columns(3)
cc1.metric("ìœ ì„ ", f"{counts['ìœ ì„ ']:,}ê±´")
cc2.metric("ì±„íŒ…", f"{counts['ì±„íŒ…']:,}ê±´")
cc3.metric("ê²Œì‹œíŒ", f"{counts['ê²Œì‹œíŒ']:,}ê±´")

if errors:
    st.error("ì—…ë¡œë“œ/ì „ì²˜ë¦¬ ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤.\n\n- " + "\n- ".join(errors))

can_save = (len(dfs) > 0) and (len(errors) == 0)

st.caption("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ë¯¸ë¦¬ë³´ê¸° ë° ì €ì¥ ë²„íŠ¼ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")

if dfs:
    st.markdown("#### ë¯¸ë¦¬ë³´ê¸°(í†µí•© ì „, ìƒìœ„ 80í–‰)")
    preview = pd.concat(dfs, ignore_index=True).head(80)
    st.dataframe(preview, use_container_width=True)

st.divider()

btn = st.button("ğŸ’¾ master ì €ì¥(í†µí•©)", disabled=not can_save, use_container_width=True)

if btn:
    t0 = time.perf_counter()
    with st.spinner("í†µí•©/ì €ì¥ ì¤‘..."):
        merged = pd.concat(dfs, ignore_index=True)

        merged = merged[REQUIRED_COLS + ["ì±„ë„"]].copy()
        merged = merged.dropna(subset=["ë‚ ì§œ"]).copy()

        out = io.BytesIO()
        with pd.ExcelWriter(out, engine="openpyxl") as w:
            merged.to_excel(w, index=False, sheet_name="master")

        b = out.getvalue()
        elapsed = time.perf_counter() - t0

        meta = {
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "rows": int(len(merged)),
            "save_seconds": round(float(elapsed), 3),
        }

        save_master_bytes(b, meta)

    st.success("ì €ì¥ ì™„ë£Œ! ì™¼ìª½ ë©”ë‰´ì—ì„œ appì„ ëˆŒëŸ¬ì£¼ì„¸ìš” ğŸ‘ˆ")
    st.caption(f"ì €ì¥ ì‹œê°„: {elapsed:.2f}ì´ˆ / ì €ì¥ rows: {len(merged):,}")
    time.sleep(0.2)
    st.rerun()
